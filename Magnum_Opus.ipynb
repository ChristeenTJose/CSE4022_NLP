{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Magnum Opus.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8omz4v5KnEuDWvgCqh1rK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChristeenTJose/CSE4022_NLP/blob/master/Magnum_Opus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAvoEXqWW3jw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "nltk.download('all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q06wyZGKXs_K",
        "colab_type": "text"
      },
      "source": [
        "# Wikipedia explanation for Magnum opus (alchemy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3Z7vGBrXGjD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc1='''The Great Work (Latin: Magnum opus) is an alchemical term for the process \n",
        "of working with the prima materia to create the philosopher's stone. \n",
        "It has been used to describe personal and spiritual transmutation in the Hermetic tradition, \n",
        "attached to laboratory processes and chemical color changes, used as a model for the individuation process, \n",
        "and as a device in art and literature. The magnum opus has been carried forward in New Age and \n",
        "neo-Hermetic movements which sometimes attached new symbolism and significance to the processes.'''"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlahWcg_X-gz",
        "colab_type": "text"
      },
      "source": [
        "# Wikipedia explanation for Great Work (Hermeticism)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pdtq-obXMhx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc2='''The term Great Work (magnum opus) is a term used in Hermeticism and \n",
        "occult traditions descended from it, most prominently Thelema. \n",
        "The Great Work signifies the spiritual path towards self-transcendence in its entirety. \n",
        "This is the process of bringing unconscious complexes into the conscious awareness, \n",
        "in order to integrate them back into oneself. Accomplishing the Great Work, \n",
        "symbolized as the creation of the Philosopher's Stone, represents the culmination of the \n",
        "spiritual path, the attainment of enlightenment, or the rescue of the \n",
        "human soul from the unconscious forces which bind it.'''"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaM6hWX3Y17t",
        "colab_type": "text"
      },
      "source": [
        "# Part 1: With Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miWvDjcRY1RS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import LancasterStemmer\n",
        "LS=LancasterStemmer()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRoVb_IgYtDR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b7edc779-d61f-429a-82d7-d7eaa3e45e65"
      },
      "source": [
        "Stem1=[LS.stem(i) for i in doc1.split()]\n",
        "Stem1=\" \".join(Stem1)\n",
        "Stem1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the gre work (latin: magn opus) is an alchem term for the process of work with the prim mater to cre the philosopher's stone. it has been us to describ person and spirit transmut in the hermet tradition, attach to lab process and chem col changes, us as a model for the individu process, and as a dev in art and literature. the magn op has been carry forward in new ag and neo-hermetic mov which sometim attach new symbol and sign to the processes.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8XSegr5angw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0960be13-a2a0-4057-8563-b89d9e38476c"
      },
      "source": [
        "Stem2=[LS.stem(i) for i in doc2.split()]\n",
        "Stem2=\" \".join(Stem2)\n",
        "Stem2"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"the term gre work (magnum opus) is a term us in hermet and occult tradit descend from it, most promin thelema. the gre work sign the spirit path toward self-transcendence in it entirety. thi is the process of bring unconscy complex into the conscy awareness, in ord to integr them back into oneself. accompl the gre work, symbol as the cre of the philosopher's stone, repres the culmin of the spirit path, the attain of enlightenment, or the rescu of the hum soul from the unconscy forc which bind it.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1_iDeJobOyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect=CountVectorizer(binary=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XRoTbMHbtnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = [Stem1,Stem2]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOnvkRfnbuPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "0f83df00-608b-4016-e68b-fc4b42db9c1b"
      },
      "source": [
        "vect.fit(corpus)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTLXpzdtb22c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6dea1099-d7b1-4802-9fa5-01c988cb9ecf"
      },
      "source": [
        "vocab=vect.vocabulary_\n",
        "len(vocab)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daANuI71dBUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0261792-9d17-4f6f-8db7-e556223e6322"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity = cosine_similarity(vect.transform([Stem1]).toarray(), vect.transform([Stem2]).toarray())\n",
        "similarity"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.38602432]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDMQFsPLeDUR",
        "colab_type": "text"
      },
      "source": [
        "# Part 2: Without Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DD_B_faBeciU",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect=CountVectorizer(binary=True)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pgLiQq7becii",
        "colab": {}
      },
      "source": [
        "corpus = [doc1,doc2]"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fOqKQdCFecit",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "a7349d9d-6a64-47d1-8ddb-1cdfa0b39615"
      },
      "source": [
        "vect.fit(corpus)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer(analyzer='word', binary=True, decode_error='strict',\n",
              "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
              "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
              "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
              "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I_z44me9eci4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4269590-7383-4ed7-9abf-462dc8efd626"
      },
      "source": [
        "vocab=vect.vocabulary_\n",
        "len(vocab)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WUxokmmNecjB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae93f1b9-f904-4844-ebbd-319010c3085b"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "similarity = cosine_similarity(vect.transform([doc1]).toarray(), vect.transform([doc2]).toarray())\n",
        "similarity"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.33353871]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccZ8D3Ondws0",
        "colab_type": "text"
      },
      "source": [
        "# Results:\n",
        "## With Stemming: \n",
        "  * Vocabulary Size = 92\n",
        "  * Cosine Similarity = 0.38602432\n",
        "\n",
        "## Without Stemming: \n",
        "  * Vocabulary Size = 95\n",
        "  * Cosine Similarity = 0.33353871\n",
        "\n",
        "## We can observe an increase in Cosine Similarity with Stemming. Also the vocabulary size decreases on stemming as multiple words with the same root are eliminated."
      ]
    }
  ]
}